{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa108161-6352-4d2d-b2c9-cad24879b579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --force-reinstall amazon-textract-textractor==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "5d14636c-4f02-4b2d-874a-cc44de0c85c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from textractor import Textractor\n",
    "from textractor.visualizers.entitylist import EntityList\n",
    "from textractor.data.constants import TextractFeatures\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "# Create the bedrock runtime to invoke LLM\n",
    "from botocore.config import Config\n",
    "config = Config(\n",
    "    read_timeout=600, #this timeout determines the maximum time (secs) allowed for the client to wait for data to be received from the server. \n",
    "    retries = dict(\n",
    "        max_attempts = 5 ## maximum number of retry attempts that will be made on a single request\n",
    "    )\n",
    ")\n",
    "import boto3\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name='us-east-1',config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "8144b0ae-4209-4a0d-aa71-6fa8097d1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bedrock_streemer(response,model):\n",
    "    stream = response.get('body')\n",
    "    answer = \"\"\n",
    "    i = 1\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                if 'claude' in model.lower():\n",
    "                    text = chunk_obj['completion']\n",
    "                if 'titan' in model.lower():\n",
    "                    text = chunk_obj[\"outputText\"]\n",
    "                if 'cohere' in model.lower():\n",
    "                    text = chunk_obj[\"generations\"][0]['text']\n",
    "                if 'llama2' in model.lower():\n",
    "                    text = chunk_obj[\"generation\"]\n",
    "                answer+=text\n",
    "                print(text, end=\"\")             \n",
    "                i+=1\n",
    "    return answer\n",
    "\n",
    "def _get_emb_(passage, model):\n",
    "    if \"titan\" in model:\n",
    "        response = bedrock_runtime.invoke_model(body=json.dumps({\"inputText\":passage}),\n",
    "                                    modelId=\"amazon.titan-embed-text-v1\", \n",
    "                                    accept=\"application/json\", \n",
    "                                    contentType=\"application/json\")\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        embedding=response_body['embedding']\n",
    "    elif \"all-mini-lm\" in model:\n",
    "        payload = {'text_inputs': [passage]}\n",
    "        payload = json.dumps(payload).encode('utf-8')\n",
    "\n",
    "        response = SAGEMAKER.invoke_endpoint(EndpointName=\"ALL MINI LM v6 SAGEMAKER ENDPOINT\", \n",
    "                                                    ContentType='application/json',  \n",
    "                                                    Body=payload)\n",
    "\n",
    "        model_predictions = json.loads(response['Body'].read())\n",
    "        embedding = model_predictions['embedding'][0]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353848f-6a67-4f7a-b6fa-0a062f61457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineIterator:\n",
    "    \"\"\"\n",
    "    A helper class for parsing the byte stream input. \n",
    "    \n",
    "    The output of the model will be in the following format:\n",
    "    ```\n",
    "    b'{\"outputs\": [\" a\"]}\\n'\n",
    "    b'{\"outputs\": [\" challenging\"]}\\n'\n",
    "    b'{\"outputs\": [\" problem\"]}\\n'\n",
    "    ...\n",
    "    ```\n",
    "    \n",
    "    While usually each PayloadPart event from the event stream will contain a byte array \n",
    "    with a full json, this is not guaranteed and some of the json objects may be split across\n",
    "    PayloadPart events. For example:\n",
    "    ```\n",
    "    {'PayloadPart': {'Bytes': b'{\"outputs\": '}}\n",
    "    {'PayloadPart': {'Bytes': b'[\" problem\"]}\\n'}}\n",
    "    ```\n",
    "    \n",
    "    This class accounts for this by concatenating bytes written via the 'write' function\n",
    "    and then exposing a method which will return lines (ending with a '\\n' character) within\n",
    "    the buffer via the 'scan_lines' function. It maintains the position of the last read \n",
    "    position to ensure that previous bytes are not exposed again. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord('\\n'):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if 'PayloadPart' not in chunk:\n",
    "                print('Unknown event type:' + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk['PayloadPart']['Bytes'])\n",
    "            \n",
    "def jumpstart_streemer(output):\n",
    "    answer=\"\"\n",
    "    stop_token = '<|endoftext|>'\n",
    "    event_stream = output['Body']\n",
    "    start_json = b'{'\n",
    "    for line in LineIterator(event_stream):\n",
    "        if line != b'' and start_json in line:\n",
    "            data = json.loads(line[line.find(start_json):].decode('utf-8'))\n",
    "            if data['token']['text'] != stop_token:\n",
    "                answer+=data['token']['text']\n",
    "                print(data['token']['text'], end=\"\")  \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac6822-8ebb-411e-ba31-a31e27383604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data to s3\n",
    "!aws s3 cp amzn-20221231.pdf s3://BUCKET-NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "b11f468c-bd49-488e-834c-7ec037d4a6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extractor = Textractor(region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "5c1d6899-82bd-49aa-8d64-ff4ebfdb235b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file=\"s3://BUCKET/amzn-20221231.pdf\"\n",
    "doc_id=file_name = os.path.basename(file)\n",
    "\n",
    "document = extractor.start_document_analysis(\n",
    "    file_source=file,\n",
    "    features=[TextractFeatures.LAYOUT,TextractFeatures.TABLES],\n",
    "    client_request_token=doc_id.split('.')[0],\n",
    "    save_image=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1f086761-25bd-4535-b1b1-10724abceae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Intangible Assets \n",
      "\n",
      "Acquired identifiable intangible assets are valued primarily by using discounted cash flows. These assets are included within \"Other assets\" on our consolidated balance sheets and consist of the following (in millions): \n",
      "\n",
      "\n",
      "\n",
      "<tables><table>\tDecember 31, \t\t\t\t\t\t\n",
      "\t2021 \t\t\t2022 \t\t\t\n",
      "\tAcquired Intangibles, Gross (1) \tAccumulated Amortization (1) \tAcquired Intangibles, Net \tAcquired Intangibles, Gross (1) \tAccumulated Amortization (1) \tAcquired Intangibles, Net \tWeighted Average Life Remaining \n",
      "Finite-lived intangible assets (2): \t\t\t\t\t\t\t\n",
      "Marketing-related \t$ 2,286 \t$ (548) \t$ 1,738 \t$ 2,407 \t$ (601) \t$ 1,806 \t18.6 \n",
      "Contract-based \t2,327 \t(565) \t1,762 \t3,661 \t(813) \t2,848 \t12.8 \n",
      "Technology- and content-based \t976 \t(610) \t366 \t883 \t(643) \t240 \t3.2 \n",
      "Customer-related \t197 \t(103) \t94 \t184 \t(128) \t56 \t2.2 \n",
      "Total finite-lived intangible assets \t$ 5,786 \t$ (1,826) \t$ 3,960 \t$ 7,135 \t$ (2,185) \t$ 4,950 \t14.4 \n",
      "IPR&D and other (3) \t$ 1,147 \t\t$ 1,147 \t$ 1,147 \t\t$ 1,147 \t\n",
      "Total acquired intangibles \t$ 6,933 \t$ (1,826) \t$ 5,107 \t$ 8,282 \t$ (2,185) \t$ 6,097 \t\n",
      "</table>\n",
      "\n",
      "\n",
      "\n",
      "<list>(1) Excludes the original cost and accumulated amortization of fully-amortized intangibles. \n",
      "(2) Finite-lived intangible assets, excluding acquired video content, have estimated useful lives of between one and twenty-five years, and are being amortized to operating expenses on a straight-line basis. \n",
      "(3) Intangible assets acquired in a business combination that are in-process and used in research and development activities are considered indefinite-lived until the completion or abandonment of the research and development efforts. Once the research and development efforts are completed, we determine the useful life and begin amortizing the assets. </list>\n",
      "\n",
      "Amortization expense for acquired finite-lived intangibles was $509 million, $512 million, and $604 million in 2020, 2021, and 2022. Expected future amortization expense of acquired finite-lived intangible assets as of December 31, 2022 is as follows (in millions): \n",
      "\n",
      "Year Ended December 31, \n",
      "\n",
      "\n",
      "\n",
      "<tables><table>2023 \t$ 530 \n",
      "2024 \t456 \n",
      "2025 \t371 \n",
      "2026 \t324 \n",
      "2027 \t314 \n",
      "Thereafter \t2,955 \n",
      "\t$ 4,950 \n",
      "</table>\n",
      "\n",
      "\n",
      "\n",
      "55 \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textractor.data.text_linearization_config import TextLinearizationConfig\n",
    "\n",
    "config = TextLinearizationConfig(\n",
    "    hide_figure_layout=True,\n",
    "    title_prefix=\"<title> \",\n",
    "     title_suffix=\"</title> \",\n",
    "    hide_header_layout=True,\n",
    "    # section_header_prefix=\"<header>\",\n",
    "    # section_header_suffix=\"</header>\",\n",
    "    # table_linearization_format=\"markdown\", \n",
    "    table_prefix=\"<tables><table>\",\n",
    "    table_suffix=\"</table>\",\n",
    "# table_layout_prefix=\"<table_layout>\",\n",
    "# table_layout_suffix=\"</table_layout>\",\n",
    "    # table_column_separator=\"|\",\n",
    "    # table_tabulate_format = 'github',\n",
    "    list_layout_prefix=\"<list>\",\n",
    "    list_layout_suffix=\"</list>\",\n",
    "    hide_footer_layout=True,\n",
    "    hide_page_num_layout=True,\n",
    "    # list_element_prefix=\"&&&\",\n",
    "    # list_element_suffix=\"%%%%\"\n",
    ")\n",
    "\n",
    "print(document.pages[84].get_text(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "5a1806be-76d0-42b1-b064-70a95cc7daf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_list_items_(items):\n",
    "    parts = re.split(\"(<list>|</list>)\", items)  \n",
    "    output = []\n",
    "\n",
    "    inside_list = False\n",
    "    list_item = \"\"\n",
    "\n",
    "    for p in parts:\n",
    "        if p == \"<list>\":\n",
    "            inside_list = True\n",
    "            # output.append(p)\n",
    "            list_item=p\n",
    "        elif p == \"</list>\":\n",
    "            inside_list = False\n",
    "            list_item += p\n",
    "            output.append(list_item)\n",
    "            list_item = \"\" \n",
    "        elif inside_list:\n",
    "            list_item += p.strip()\n",
    "        else:\n",
    "            output.extend(p.split('\\n'))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "a011ade1-bd57-49e3-a531-297e3c34d4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We filter through each page with a table and replace that free text table with a csv formatted table \n",
    "demarcated by <table> xml tags\n",
    "\"\"\"\n",
    "csv_seperator=\"|\"\n",
    "document_holder={}\n",
    "table_page={}\n",
    "count=0\n",
    "for ids,page in enumerate(document.pages):\n",
    "\n",
    "    table_count=len([word for word in page.get_text(config=config).split() if \"<tables><table>\" in word]) # get the number of table in the extracted document page by header we set earlier\n",
    "    assert table_count==len(page.tables) # check that number of tables per page is same as tables extracted by textract TABLE feature\n",
    "    content=page.get_text(config=config).split(\"<tables>\")\n",
    "    document_holder[ids]=[]    \n",
    "    for idx,item in enumerate(content):\n",
    "        if \"<table>\" in item:     \n",
    "\n",
    "            df0=document.tables[count].to_pandas(use_columns=False).to_csv(header=False, index=None,sep=csv_seperator)\n",
    "            row_count=len([x for x in df0.split(\"\\n\") if x]) #Check the number of rows in the parsed table to determine how to read the table headers. if table row count is 1 then headers is obviously at 0 else headers may or may not be at 0\n",
    "            if row_count>1:\n",
    "                if not all(value.strip() == '' for value in df0.split(\"\\n\")[0].split(csv_seperator)): #Check if the first row in the csv is empty headers due to the way Textract parses the csv at times (with empty column headers while true headers are at index=1)\n",
    "                    row_count=1 # if true column headers sit at row index 0 set row_count=1 else true column headers sit at row index 1\n",
    "            df=pd.read_csv(io.StringIO(df0), sep=csv_seperator, \n",
    "                           header=0 if row_count==1 else 1, keep_default_na=False) # read table with appropiate column headers\n",
    "            df.rename(columns=lambda x: '' if x.startswith('Unnamed:') else x, inplace=True) # replace pandas \"unnamed\" placeholder for empty column names with empty string\n",
    "            table=df.to_csv(index=None, sep=csv_seperator)\n",
    "            if ids in table_page:\n",
    "                table_page[ids].append(table)\n",
    "            else:\n",
    "                table_page[ids]=[table]\n",
    "            pattern = re.compile(r'<table>(.*?)(</table>)', re.DOTALL)  ## scoop the table csv string from other non-tabular text\n",
    "            data=item\n",
    "            table_match = re.search(pattern, data)\n",
    "            table_data = table_match.group(1) if table_match else ''  ## table\n",
    "            remaining_content = data[table_match.end():] if table_match else data ## non-tabular text\n",
    "            content[idx]=f\"<table>{table}</table>\" ## attach xml tags to differentiate table from other text\n",
    "            count+=1\n",
    "            if \"<list>\" in remaining_content: # keep list item as a single item in the python list\n",
    "                output=split_list_items_(remaining_content)\n",
    "                output=[x.strip() for x in output if x.strip()]\n",
    "                document_holder[ids].extend([content[idx]]+output)           \n",
    "            else:\n",
    "                document_holder[ids].extend([content[idx]]+[x.strip() for x in remaining_content.split('\\n') if x.strip()]) # split other text by new line to be independent items in the python list.\n",
    "        else:   \n",
    "            if \"<list>\" in item and \"<table>\" not in item:   \n",
    "                output=split_list_items_(item)\n",
    "                output=[x.strip() for x in output if x.strip()]\n",
    "                document_holder[ids].extend(output)\n",
    "            else:\n",
    "                document_holder[ids].extend([x.strip() for x in item.split(\"\\n\") if x.strip()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "f279709f-fe7a-4065-94c7-5efeeab8d0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intangible Assets\n",
      "Acquired identifiable intangible assets are valued primarily by using discounted cash flows. These assets are included within \"Other assets\" on our consolidated balance sheets and consist of the following (in millions):\n",
      "<table>|December 31, ||||||\n",
      "|2021 |||2022 |||\n",
      "|Acquired Intangibles, Gross (1) |Accumulated Amortization (1) |Acquired Intangibles, Net |Acquired Intangibles, Gross (1) |Accumulated Amortization (1) |Acquired Intangibles, Net |Weighted Average Life Remaining \n",
      "Finite-lived intangible assets (2): |||||||\n",
      "Marketing-related |$ 2,286 |$ (548) |$ 1,738 |$ 2,407 |$ (601) |$ 1,806 |18.6 \n",
      "Contract-based |2,327 |(565) |1,762 |3,661 |(813) |2,848 |12.8 \n",
      "Technology- and content-based |976 |(610) |366 |883 |(643) |240 |3.2 \n",
      "Customer-related |197 |(103) |94 |184 |(128) |56 |2.2 \n",
      "Total finite-lived intangible assets |$ 5,786 |$ (1,826) |$ 3,960 |$ 7,135 |$ (2,185) |$ 4,950 |14.4 \n",
      "IPR&D and other (3) |$ 1,147 ||$ 1,147 |$ 1,147 ||$ 1,147 |\n",
      "Total acquired intangibles |$ 6,933 |$ (1,826) |$ 5,107 |$ 8,282 |$ (2,185) |$ 6,097 |\n",
      "</table>\n",
      "<list>(1) Excludes the original cost and accumulated amortization of fully-amortized intangibles. \n",
      "(2) Finite-lived intangible assets, excluding acquired video content, have estimated useful lives of between one and twenty-five years, and are being amortized to operating expenses on a straight-line basis. \n",
      "(3) Intangible assets acquired in a business combination that are in-process and used in research and development activities are considered indefinite-lived until the completion or abandonment of the research and development efforts. Once the research and development efforts are completed, we determine the useful life and begin amortizing the assets.</list>\n",
      "Amortization expense for acquired finite-lived intangibles was $509 million, $512 million, and $604 million in 2020, 2021, and 2022. Expected future amortization expense of acquired finite-lived intangible assets as of December 31, 2022 is as follows (in millions):\n",
      "Year Ended December 31,\n",
      "<table>2023 |$ 530 \n",
      "2024 |456 \n",
      "2025 |371 \n",
      "2026 |324 \n",
      "2027 |314 \n",
      "Thereafter |2,955 \n",
      "|$ 4,950 \n",
      "</table>\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(document_holder[84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "919c8154-00b5-466b-b3f6-54f91cde19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "max_words = 200\n",
    "chunks = {}\n",
    "entire_list_chunk=[]\n",
    "table_header_dict={} ## hold table headers to be used for chunk indexing\n",
    "list_header_dict={}\n",
    "overlap=50\n",
    "for page, lines in document_holder.items():\n",
    "    page_chunks = []\n",
    "    current_chunk = []\n",
    "    num_words = 0   \n",
    "    start_page=0\n",
    "    TITLE=None\n",
    "    for line in lines:\n",
    "        if line.strip()!= '':\n",
    "            # COmment this code block out if you dont want to include topic chunkimg\n",
    "            if \"<title>\" in line:   \n",
    "                TITLE=line.split(\"<title>\")[-1].split(\"</title>\")[0]\n",
    "                line=TITLE\n",
    "                TITLE=TITLE.upper()               \n",
    "            \n",
    "\n",
    "            if len(current_chunk)<2 and entire_list_chunk and start_page==0:    \n",
    "                cumulative_word_count = 0\n",
    "                items_within_threshold = 0\n",
    "                \n",
    "                # Iterate through the list from the bottom up and add up to 50 words from previous page\n",
    "                for item in reversed(entire_list_chunk[-1]):\n",
    "                    words = item.split()\n",
    "                    if cumulative_word_count + len(words) <= overlap:\n",
    "                        cumulative_word_count += len(words)\n",
    "                        items_within_threshold += 1\n",
    "                        current_chunk.insert(0, item)  # Insert at the beginning to maintain order\n",
    "                    else:\n",
    "                        break\n",
    "                first_page_portion=True\n",
    "                num_words=cumulative_word_count\n",
    "                start_page=1\n",
    "\n",
    "            next_num_words = num_words + len(re.findall(r'\\w+', line))  \n",
    "\n",
    "            if  \"<table>\" not in line and \"<list>\" not in line:                \n",
    "                \n",
    "                if next_num_words > max_words:\n",
    "                    if TITLE :\n",
    "                        if first_page_portion:\n",
    "                            first_page_portion=False\n",
    "                        else:\n",
    "                            current_chunk.insert(0, TITLE.strip())\n",
    "                        \n",
    "                    page_chunks.append(current_chunk)\n",
    "                    entire_list_chunk.append(current_chunk)\n",
    "                    current_chunk = []\n",
    "                    num_words = 0\n",
    "\n",
    "                current_chunk.append(line)    \n",
    "                num_words += len(re.findall(r'\\w+', line))\n",
    "                \n",
    "            \"\"\"\n",
    "            Goal is to segment out table items and chunks intelligently.\n",
    "            We chunk the table by rows and for each chunk of the table we append the table column headers\n",
    "            and table headers if any. This way we preserve the table information across each chunks.\n",
    "            This will help improve semantic search where all the chunks relating to a table would be in the \n",
    "            top k=n response giving the LLM mcomplet information on the table.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            if \"<table>\" in line:\n",
    "                # Get table header which is usually line before table in document\n",
    "                line_index=lines.index(line)\n",
    "                if line_index!=0 and \"<table>\" not in lines[line_index-1] and \"<list>\" not in lines[line_index-1]: #Check if table is first item on the page, then they wont be a header (header may be included it table) and also if table is the the last item in the list\n",
    "                    header=lines[line_index-1]\n",
    "                else:\n",
    "                    header=\"\"\n",
    "                \n",
    "                if page in table_header_dict:\n",
    "                    table_header_dict[page].append(header)\n",
    "                else:\n",
    "                    table_header_dict[page]=[header]\n",
    "\n",
    "                table = line.split(\"<table>\")[-1].split(\"</table>\")[0] # get table from demarcators     \n",
    "                df=pd.read_csv(io.StringIO(table), sep=csv_seperator, keep_default_na=False)\n",
    "                df.rename(columns=lambda x: '' if x.startswith('Unnamed:') else x, inplace=True)\n",
    "\n",
    "                table_chunks = []\n",
    "                curr_chunk = [df.columns.to_list()] #start current chunk with table column names    \n",
    "                words=len(re.findall(r'\\w+', str(current_chunk)+\" \"+str(curr_chunk)))  \n",
    "                # Iterate through the rows in the table\n",
    "                for row in df.itertuples():\n",
    "                    curr_chunk.append(row)         \n",
    "                    words+=len(re.findall(r'\\w+', str(row)))#len(re.findall(r'\\w+', \" \".join([str(x) for x in row])))\n",
    "\n",
    "                    if words > max_words:\n",
    "                        # print(words,page, end=\"\\n\")                        \n",
    "                        table_chunks.append(\"\\n\".join([\"|\".join(str(x) for x in curr_chunk[0])] + [\"|\".join(str(x) for x in r) for r in curr_chunk[1:]])) #join chunk lines together to for a csv                   \n",
    "                        words = len(re.findall(r'\\w+', str(curr_chunk[0]))) # set word count to word length of column header names\n",
    "                        tab_chunk=\"\\n\".join([\"|\".join(str(x) for x in curr_chunk[0])] + [\"|\".join(str(x) for x in r) for r in curr_chunk[1:]]) #join chunk lines together to for a csv\n",
    "                        \n",
    "                        if header: #If header  attach header to table                         \n",
    "                            if current_chunk and current_chunk[-1]==header: #check if header is in the chunk and remove to avoid duplicacy of header in chunk                        \n",
    "                                current_chunk.pop(-1)\n",
    "                            \n",
    "                            header=header+\"\\n\" if not header.strip().endswith('\\n') else header  # add new line char to seperate from table  \n",
    "                            if TITLE:\n",
    "                                current_chunk.insert(0, TITLE.strip())\n",
    "                            current_chunk.extend([header]+[tab_chunk]) #if current_chunk and header!=current_chunk[-1] else current_chunk.extend([tab_chunk])\n",
    "                            page_chunks.append(current_chunk)                            \n",
    "                            entire_list_chunk.append([header]+table_chunks) #if current_chunk and header!=current_chunk[-1] else entire_list_chunk.append(table_chunks)\n",
    "                        else:\n",
    "                            if TITLE:\n",
    "                                current_chunk.insert(0, TITLE.strip())\n",
    "                            current_chunk.extend([tab_chunk])\n",
    "                            page_chunks.append(current_chunk)\n",
    "                            entire_list_chunk.append(table_chunks)\n",
    "                       \n",
    "                        num_words=0\n",
    "                        current_chunk=[]\n",
    "                        curr_chunk = [curr_chunk[0]]\n",
    "\n",
    "                if curr_chunk != [df.columns.to_list()] and lines.index(line) == len(lines)-1: #if table chunk still remaining and table is last item in page append as last chunk\n",
    "                    table_chunks.append(\"\\n\".join([\"|\".join(str(x) for x in curr_chunk[0])] + [\"|\".join(str(x) for x in r) for r in curr_chunk[1:]]))\n",
    "                    tab_chunk=\"\\n\".join([\"|\".join(str(x) for x in curr_chunk[0])] + [\"|\".join(str(x) for x in r) for r in curr_chunk[1:]])\n",
    "                    if header: \n",
    "                        if current_chunk and current_chunk[-1]==header: #check if header is in the chunk and remove to avoid duplicacy of header in chunk\n",
    "                            current_chunk.pop(-1)\n",
    "                        header=header+\"\\n\" if not header.strip().endswith('\\n') else header \n",
    "                        if TITLE:\n",
    "                            current_chunk.insert(0, TITLE.strip())\n",
    "                        current_chunk.extend([header]+[tab_chunk])\n",
    "                        page_chunks.append(current_chunk)\n",
    "                        entire_list_chunk.append([header]+table_chunks)\n",
    "                    else:\n",
    "                        if TITLE:\n",
    "                            current_chunk.insert(0, TITLE.strip())\n",
    "                        current_chunk.extend([tab_chunk])\n",
    "                        page_chunks.append(current_chunk)\n",
    "                        entire_list_chunk.append(table_chunks)\n",
    "                    num_words=0\n",
    "                    current_chunk=[]\n",
    "                elif curr_chunk != [df.columns.to_list()] and lines.index(line) != len(lines)-1: #if table is not last item in page and max word threshold is not reached, send no next loop\n",
    "                    table_chunks.append(\"\\n\".join([\"|\".join(str(x) for x in curr_chunk[0])] + [\"|\".join(str(x) for x in r) for r in curr_chunk[1:]]))\n",
    "                    tab_chunk=\"\\n\".join([\"|\".join(str(x) for x in curr_chunk[0])] + [\"|\".join(str(x) for x in r) for r in curr_chunk[1:]])\n",
    "                    if header:               \n",
    "                        if current_chunk and current_chunk[-1]==header: #check if header is in the chunk and remove to avoid duplicacy of header in chunk\n",
    "                            current_chunk.pop(-1)\n",
    "                        header=header+\"\\n\" if not header.strip().endswith('\\n') else header \n",
    "                        current_chunk.extend([header]+[tab_chunk])\n",
    "                    else:\n",
    "                        current_chunk.extend([tab_chunk])                  \n",
    "                    num_words=words\n",
    "            \n",
    "            \"\"\"\n",
    "            Goal is to segment out list items and chunk intelligently.\n",
    "            We chunk each list by items in the list and \n",
    "            for each list chunk we append the list header to the chunk to preserve the information of the list across chunks.\n",
    "            This would boost retrieval process where question pertaining to a list will have all list chunks within\n",
    "            the topK=n responses.\n",
    "            \"\"\"\n",
    "            \n",
    "            if \"<list>\" in line:\n",
    "                # Get list header which is usually line before list in document\n",
    "                line_index=lines.index(line)\n",
    "                if line_index!=0 and \"<table>\" not in lines[line_index-1] and \"<list>\" not in lines[line_index-1]: #Check if table or list is the previous item on the page, then they wont be a header\n",
    "                    header=lines[line_index-1]\n",
    "                else:\n",
    "                    header=\"\"           \n",
    "                list_pattern = re.compile(r'<list>(.*?)</list>', re.DOTALL)   ## Grab all list contents within the list xml tags        \n",
    "                list_match = re.search(list_pattern, line)\n",
    "                list_ = list_match.group(1)\n",
    "                list_lines=list_.split(\"\\n\")                \n",
    "\n",
    "                curr_chunk = []  \n",
    "                words=len(re.findall(r'\\w+', str(current_chunk)))  #start word count from any existing chunk\n",
    "                # Iterate through the items in the list\n",
    "                for item in list_lines:\n",
    "                    curr_chunk.append(item)         \n",
    "                    words+=len(re.findall(r'\\w+', item)) \n",
    "\n",
    "                    if words >= max_words: #  \n",
    "                        words = 0 # restart word count to zero\n",
    "                        \n",
    "                        list_chunk=\"\\n\".join(curr_chunk)\n",
    "                        if header: # If header  attach header to table                         \n",
    "                            if current_chunk and current_chunk[-1]==header: #check if header is in the chunk and remove to avoid duplicacy of header in chunk                        \n",
    "                                current_chunk.pop(-1)  \n",
    "                            header=header+\"\\n\" if not header.strip().endswith('\\n') else header                            \n",
    "                            if TITLE:\n",
    "                                current_chunk.insert(0, TITLE.strip())                          \n",
    "                            current_chunk.extend([header]+[list_chunk]) \n",
    "                            page_chunks.append(current_chunk)                            \n",
    "                            entire_list_chunk.append([header]+[list_chunk])\n",
    "                        else:\n",
    "                            if TITLE:\n",
    "                                current_chunk.insert(0, TITLE.strip())\n",
    "                            current_chunk.extend([list_chunk])\n",
    "                            page_chunks.append(current_chunk)\n",
    "                            entire_list_chunk.append([list_chunk])\n",
    "                       \n",
    "                        num_words=0\n",
    "                        current_chunk=[]\n",
    "                        curr_chunk = []\n",
    "\n",
    "                if curr_chunk  and lines.index(line) == len(lines)-1: #if list chunk still remaining and list is last item in page append as last chunk\n",
    "                    list_chunk=\"\\n\".join(curr_chunk)\n",
    "                    if header: \n",
    "                        if current_chunk and current_chunk[-1]==header: #check if header is in the chunk and remove to avoid duplicacy of header in chunk\n",
    "                            current_chunk.pop(-1)\n",
    "                        header=header+\"\\n\" if not header.strip().endswith('\\n') else header\n",
    "                        if TITLE:\n",
    "                            current_chunk.insert(0, TITLE.strip())\n",
    "                        current_chunk.extend([header]+[list_chunk])\n",
    "                        page_chunks.append(current_chunk)\n",
    "                        entire_list_chunk.append([header]+[list_chunk])\n",
    "                    else:\n",
    "                        if TITLE:\n",
    "                            current_chunk.insert(0, TITLE.strip())\n",
    "                        current_chunk.extend([list_chunk])\n",
    "                        page_chunks.append(current_chunk)\n",
    "                        entire_list_chunk.append([list_chunk])\n",
    "                    num_words=0\n",
    "                    current_chunk=[]\n",
    "                elif curr_chunk and lines.index(line) != len(lines)-1: #if list is not last item in page and max word threshold is not reached, send to next loop          \n",
    "                    list_chunk=\"\\n\".join(curr_chunk)\n",
    "                    if header:               \n",
    "                        if current_chunk and current_chunk[-1]==header: #check if header is in the chunk and remove to avoid duplicacy of header in chunk\n",
    "                            current_chunk.pop(-1)\n",
    "                        header=header+\"\\n\" if not header.strip().endswith('\\n') else header                         \n",
    "                        current_chunk.extend([header]+[list_chunk])\n",
    "                    else:\n",
    "                        current_chunk.extend([list_chunk])                  \n",
    "                    num_words=words\n",
    "            \n",
    "            \n",
    "    if current_chunk:\n",
    "        if TITLE:\n",
    "            current_chunk.insert(0, TITLE.strip())\n",
    "        page_chunks.append(current_chunk)\n",
    "        entire_list_chunk.append(current_chunk)\n",
    "        current_chunk=[]\n",
    "    chunks[page] = page_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "9501b756-ba00-48f7-a400-49bae1d834d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "NOTE 5 - ACQUISITIONS, GOODWILL, AND ACQUIRED INTANGIBLE ASSETS\n",
      "(1) Primarily includes changes in foreign exchange rates.\n",
      "Intangible Assets\n",
      "Acquired identifiable intangible assets are valued primarily by using discounted cash flows. These assets are included within \"Other assets\" on our consolidated balance sheets and consist of the following (in millions):\n",
      "\n",
      "|December 31, ||||||\n",
      "0||2021 |||2022 |||\n",
      "1||Acquired Intangibles, Gross (1) |Accumulated Amortization (1) |Acquired Intangibles, Net |Acquired Intangibles, Gross (1) |Accumulated Amortization (1) |Acquired Intangibles, Net |Weighted Average Life Remaining \n",
      "2|Finite-lived intangible assets (2): |||||||\n",
      "3|Marketing-related |$ 2,286 |$ (548) |$ 1,738 |$ 2,407 |$ (601) |$ 1,806 |18.6 \n",
      "4|Contract-based |2,327 |(565) |1,762 |3,661 |(813) |2,848 |12.8 \n",
      "5|Technology- and content-based |976 |(610) |366 |883 |(643) |240 |3.2 \n",
      "6|Customer-related |197 |(103) |94 |184 |(128) |56 |2.2 \n",
      "\n",
      "\n",
      "Chunk 2:\n",
      "Acquired identifiable intangible assets are valued primarily by using discounted cash flows. These assets are included within \"Other assets\" on our consolidated balance sheets and consist of the following (in millions):\n",
      "\n",
      "\n",
      "|December 31, ||||||\n",
      "7|Total finite-lived intangible assets |$ 5,786 |$ (1,826) |$ 3,960 |$ 7,135 |$ (2,185) |$ 4,950 |14.4 \n",
      "8|IPR&D and other (3) |$ 1,147 ||$ 1,147 |$ 1,147 ||$ 1,147 |\n",
      "9|Total acquired intangibles |$ 6,933 |$ (1,826) |$ 5,107 |$ 8,282 |$ (2,185) |$ 6,097 |\n",
      "(1) Excludes the original cost and accumulated amortization of fully-amortized intangibles. \n",
      "(2) Finite-lived intangible assets, excluding acquired video content, have estimated useful lives of between one and twenty-five years, and are being amortized to operating expenses on a straight-line basis. \n",
      "(3) Intangible assets acquired in a business combination that are in-process and used in research and development activities are considered indefinite-lived until the completion or abandonment of the research and development efforts. Once the research and development efforts are completed, we determine the useful life and begin amortizing the assets.\n",
      "\n",
      "\n",
      "Chunk 3:\n",
      "Amortization expense for acquired finite-lived intangibles was $509 million, $512 million, and $604 million in 2020, 2021, and 2022. Expected future amortization expense of acquired finite-lived intangible assets as of December 31, 2022 is as follows (in millions):\n",
      "Year Ended December 31,\n",
      "\n",
      "2023 |$ 530 \n",
      "0|2024 |456 \n",
      "1|2025 |371 \n",
      "2|2026 |324 \n",
      "3|2027 |314 \n",
      "4|Thereafter |2,955 \n",
      "5||$ 4,950 \n",
      "55\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks[84], start=1):\n",
    "    print(f'Chunk {i}:')\n",
    "    for item in chunk:\n",
    "        print(item)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f459d61-102c-44c4-8b65-245b74c5d883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install requests-aws4auth\n",
    "# pip install opensearch-py\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "\"\"\"\n",
    "This is Amazon opensearch domain that uses IAM for authetication\n",
    "\"\"\"\n",
    "# Embedding Model\n",
    "model=\"all-mini-lm\" # other option \"titan\" #you can also use any other model in Bedrock or SageMaker Jumpstart or HuggingFace\n",
    "\n",
    "domain_endpoint = \"OPENSEARCH PROVISIONED CLUSTER ENDPOINT\"\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, \"us-east-1\", service, session_token=credentials.token)\n",
    "os_ = OpenSearch(\n",
    "    hosts = [{'host': domain_endpoint, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    timeout=120,        \n",
    "    # http_compress = True, # enables gzip compression for request bodies\n",
    "    connection_class = RequestsHttpConnection\n",
    ")\n",
    "\n",
    "# Sample Opensearch domain index mapping\n",
    "mapping = {\n",
    "  'settings': {\n",
    "    'index': {  \n",
    "      'knn': True,\n",
    "      \"knn.algo_param.ef_search\": 100,            \n",
    "    }\n",
    "      },\n",
    "\n",
    "      'mappings': {  \n",
    "        'properties': {\n",
    "          'embedding': {\n",
    "            'type': 'knn_vector', \n",
    "            'dimension':384 if \"all-mini-lm\" in model else (1536 if \"titan\" in model else None), #change as per sequence length of Embedding Model\n",
    "            \"method\": {\n",
    "              \"name\": \"hnsw\",       \n",
    "              \"space_type\": \"innerproduct\",\n",
    "              \"engine\": \"nmslib\",\n",
    "              \"parameters\": {\n",
    "                 \"ef_construction\": 256,\n",
    "                 \"m\":  48\n",
    "               }\n",
    "            }\n",
    "          },\n",
    "\n",
    "          'passage_id': {\n",
    "            'type': 'keyword'\n",
    "          },\n",
    "\n",
    "          'passage': {\n",
    "            'type': 'text'\n",
    "          },\n",
    "\n",
    "          'doc_id': {\n",
    "            'type': 'keyword'\n",
    "          },\n",
    "        \n",
    "          'table': {\n",
    "            'type': 'text'\n",
    "          },\n",
    "\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "domain_index = f\"experiment16\"    \n",
    "\n",
    "if not os_.indices.exists(index=domain_index):        \n",
    "    os_.indices.create(index=domain_index, body=mapping)\n",
    "    # Verify that the index has been created\n",
    "    if os_.indices.exists(index=domain_index):\n",
    "        print(f\"Index {domain_index} created successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to create index '{domain_index}'.\")\n",
    "else:\n",
    "    print(f'{domain_index} Index already exists!')\n",
    "\n",
    "i = 1\n",
    "import boto3\n",
    "SAGEMAKER=boto3.client('sagemaker-runtime')\n",
    "for page, chunkks in chunks.items(): # Iterate through dict with chunk page# and content\n",
    "    chunk_id = page # take care of multiple chunks in same page (*) is used as delimiter\n",
    "   \n",
    "    \n",
    "    for chunk in chunkks:\n",
    "        passage_chunk=\"\\n\".join(chunk)        \n",
    "        embedding=_get_emb_(passage_chunk, model)\n",
    "        # embedding = model_predictions['embedding'][0]\n",
    "        table=[]\n",
    "        if page in table_page:\n",
    "            for ids,item in enumerate(table_page[page]):\n",
    "                header=table_header_dict[page][ids]\n",
    "                if header.strip():\n",
    "                    header=f\"<table_header>{header}</table_header>\"\n",
    "                tsv=f\"<table>{item}</table>\"\n",
    "                table.append(header)\n",
    "                table.append(tsv)\n",
    "            table=\"\\n\".join(table)                \n",
    "        documentt = { \n",
    "            'doc_id':doc_id, #doc name\n",
    "            'passage_id': chunk_id, #page number\n",
    "            'passage': passage_chunk, \n",
    "            'embedding': embedding,\n",
    "            'table':table #table\n",
    "        }\n",
    "        try:\n",
    "            response = os_.index(index=domain_index, body=documentt)\n",
    "            i += 1\n",
    "            # Check the response to see if the indexing was successful\n",
    "            if response[\"result\"] == \"created\":\n",
    "                print(f\"Document indexed successfully with ID: {response['_id']}\")\n",
    "            else:\n",
    "                print(\"Failed to index document.\")\n",
    "        except RequestError as e:\n",
    "            logging.error(f\"Error indexing document to index '{domain_index}': {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f7c64-1ddb-4c4a-a050-67669632790b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question=\"operating income loss in 2022 for North america?\"\n",
    "\n",
    "query = {\n",
    "    'size': 3,\n",
    "    'query': {\n",
    "        \"knn\": {\n",
    "          \"embedding\": {\n",
    "            \"vector\": embedding,\n",
    "            \"k\": 3\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "response = os_.search(index=domain_index, body=query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "6c3a127e-74c4-4500-a48d-084d026108a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=response['hits']['hits']\n",
    "score = [str(x['_score']) for x in res]  #retrieval score\n",
    "passage = [x['_source']['passage'] for x in res] #retrieved passages\n",
    "page_no = [x['_source']['passage_id'] for x in res] #doc page number of chunks\n",
    "doc_name = [x['_source']['doc_id'] for x in res] # doc names\n",
    "tables=[x['_source']['table'] for x in res] # tables in the corresponding chunk doc pages\n",
    "\n",
    "## Concatenate passages and tables\n",
    "passages=\"\"\n",
    "tab=\"\"\n",
    "for  ids,text in enumerate(passage):\n",
    "    passages+=f\"<{p.ordinal(ids+1)}_passage>\\n{text}\\n</{p.ordinal(ids+1)}_passage>\\n\"\n",
    "    tab+=f\"<{p.ordinal(ids+1)}_passage_table>\\n{tables[ids]}\\n</{p.ordinal(ids+1)}_passage_table>\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb7c3cc-beb5-48e2-abaa-66b46c5e8373",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1bbeba-2fd9-4775-aec2-8a8c287e8655",
   "metadata": {},
   "source": [
    "## Bedrock Anthropic LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "edc0c8ab-5cf5-4200-829f-08c576db2d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template=f\"\"\"You are a helpful, obedient and truthful financial assistance.\n",
    "\n",
    "<document>\n",
    "{passages}\n",
    "</document>          \n",
    "\n",
    "<additional_information>\n",
    "{tab}\n",
    "</additional_information>\n",
    "\n",
    "<instructions>\n",
    "When providing your response based on the document:\n",
    "1. Understand the question to know what is being asked of you.\n",
    "2. Review the entire document provided and check if it contains relevant information to answer the question. Only pay attention to passages with relevant information.\n",
    "3. If the document is sufficient to answer the question, provide a comprehensive answer ENTIRELY based on the document provided. DO NOT make up answers not present in the document.\n",
    "4. If the answer is not available in the document, say so.\n",
    "</instructions>\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "prompt=f\"\\n\\nHuman:{prompt_template}\\n\\nAssistant: Based on the document,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e1c51-508c-4f5b-8928-b98a2a10e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='anthropic.claude-v2'\n",
    "prompts={\n",
    "  \"prompt\": prompt,\n",
    "  \"max_tokens_to_sample\": 300,\n",
    "  \"temperature\": 0.1,\n",
    "  # \"top_k\": 250,\n",
    "  # \"top_p\": 1,  \n",
    "   \n",
    "}\n",
    "prompts=json.dumps(prompts)\n",
    "response = bedrock_runtime.invoke_model_with_response_stream(body=prompts, modelId=model, accept=\"application/json\",  contentType=\"application/json\")\n",
    "output = bedrock_streemer(response,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fe1cf-998b-4469-bf08-e9b77feead7b",
   "metadata": {},
   "source": [
    "## SageMaker JumpStart Mixtral 8x7b Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "81104193-61c8-481e-ae83-0dd36fa46b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt=f\"\"\"<s><<SYS>>[INST]\n",
    "You are a helpful, obedient and truthful assistant. You will only provide answers entirely based on the document provided below.\n",
    "\n",
    "Here is a document:\n",
    "####\n",
    "{passages}\n",
    "####\n",
    "\n",
    "Here is additional information:\n",
    "####\n",
    "{tab}\n",
    "####\n",
    "\n",
    "When providing your response based on the provided document:\n",
    "1. Understand the question to know what is being asked of you.\n",
    "2. Review the entire document provided and check if it contains relevant information to answer the question. Only pay attention to sections with relevant information.\n",
    "3. If the document is sufficient to answer the question, provide a comprehensive answer ENTIRELY based on the document provided. DO NOT make up answers not present in the document.\n",
    "4. If the answer is not available in the document, say so.<</SYS>>\n",
    "\n",
    "Question: {question}[/INST]\n",
    "Answer: According to the document provided,\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476170b-492b-4b41-8e1d-afdab9b52c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "       \"inputs\": prompt,\n",
    "        \"parameters\": {\"max_new_tokens\": 300, \n",
    "                       # \"top_p\": 0.99 ,\n",
    "                       # \"temperature\": 0.1,\n",
    "                       \"return_full_text\": False,},\n",
    "    \"stream\": True\n",
    "    } \n",
    "output=SAGEMAKER.invoke_endpoint_with_response_stream(Body=json.dumps(payload), EndpointName=\"MIXTRAL ENDPOINT SAGEAMKER\",ContentType=\"application/json\")\n",
    "answer=jumpstart_streemer(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2cb09-5ef4-41dc-bbb4-05d235423f32",
   "metadata": {},
   "source": [
    "# SUMMARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce4526-8167-45bd-a0fd-dfe0ee1ba0ad",
   "metadata": {},
   "source": [
    "## Bedrock Athropic Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "ba3271d6-436f-47de-90b7-8fd37aad8121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc=\"\"\n",
    "for k,v in document_holder.items():\n",
    "    doc+=\"\\n\".join(v)\n",
    "# print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "cffad7b6-d912-490a-b44e-53af7792a018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template=f\"\"\"You are a financial analyst, great at writing summaries of company financial performance.\n",
    "\n",
    "Here is a document:\n",
    "<document>\n",
    "{doc}\n",
    "</document>\n",
    "\n",
    "Before responding:\n",
    "1. Read the document several times to ensure you understand everything.\n",
    "2. Take notes to identify the relevant information.\n",
    "\n",
    "Provide a comprehensive summary of the document.\n",
    "Your summary should include the following if available in the document:\n",
    "1. Revenue and Profitability\n",
    "2. Cash Flow\n",
    "3. Debt and Solvency\n",
    "4. Market and Industry Trends\n",
    "5. Future Outlook\n",
    "6. Risks and Contingencies\n",
    "\n",
    "Base your entire summary on the information provided in the document.\"\"\"\n",
    "prompt=f\"\\n\\nHuman:{prompt_template}\\n\\nAssistant:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "8d8d9540-2573-44be-9fac-0ec7228df875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a comprehensive summary of the Amazon.com 2022 10-K document:\n",
      "\n",
      "Revenue and Profitability\n",
      "- Amazon reported total net sales of $514 billion in 2022, up 9% from 2021. North America sales were $316 billion, up 13%. International sales were $118 billion, down 8% due to currency impacts. AWS sales were $80 billion, up 29%. \n",
      "- Operating income was $12.2 billion in 2022, down from $24.9 billion in 2021. North America had an operating loss of $2.8 billion compared to income of $7.3 billion in 2021 due to higher fulfillment and shipping costs. International had a larger operating loss of $7.7 billion. AWS operating income grew to $22.8 billion.\n",
      "- Net loss was $2.7 billion in 2022 compared to net income of $33.4 billion in 2021, primarily due to marketable equity valuation losses. \n",
      "\n",
      "Cash Flow  \n",
      "- Operating cash flow was $46.8 billion in 2022 compared to $46.3 billion in 2021. Investing cash flow was -$37.6 billion, compared to -$58.2 billion in 2021. Financing cash flow was $9.7 billion, compared to $6.3 billion in 2021.\n",
      "- Cash, cash equivalents, and marketable securities totaled $70 billion at December 31, 2022. \n",
      "\n",
      "Debt and Solvency\n",
      "- Long-term debt totaled $67.1 billion at December 31, 2022 compared to $48.7 billion at December 31, 2021.\n",
      "- The company has access to $21 billion in revolving credit facilities, of which $1 billion was drawn at December 31, 2022.\n",
      "\n",
      "Market and Industry Trends\n",
      "- Online and physical retail sales grew, driven by focus on price, selection and convenience including shipping offers. \n",
      "- AWS sales grew due to higher customer usage, despite pricing changes.\n",
      "- Advertising and subscription services revenue grew.\n",
      "- Inflation, higher interest rates, supply chain issues, and other macroeconomic factors drove up costs.\n",
      "\n",
      "Future Outlook\n",
      "- Investments continuing in fulfillment network, AWS infrastructure, and new initiatives.\n",
      "- Working to mitigate cost increases through higher sales volumes, network optimization, vendor negotiations, and operational efficiencies.\n",
      "- International expansion continues with managing regulatory challenges.\n",
      "\n",
      "Risks and Contingencies \n",
      "- Intense competition globally from physical, e-commerce, and omnichannel retailers and digital media.\n",
      "- Fluctuating economic conditions and discretionary consumer spending impact sales.\n",
      "- Significant technology investments have risks if not successful.\n",
      "- Regulatory complexity including proposals for new taxes and laws.\n",
      "- Legal claims, proceedings, and government investigations are ongoing."
     ]
    }
   ],
   "source": [
    "model='anthropic.claude-v2'\n",
    "prompts={\n",
    "  \"prompt\": prompt,\n",
    "  \"max_tokens_to_sample\": 1000,\n",
    "  \"temperature\": 0.3,\n",
    "  # \"top_k\": 250,\n",
    "  # \"top_p\": 1,  \n",
    "   \n",
    "}\n",
    "prompts=json.dumps(prompts)\n",
    "response = bedrock_runtime.invoke_model_with_response_stream(body=prompts, modelId=model, accept=\"application/json\",  contentType=\"application/json\")\n",
    "output = bedrock_streemer(response,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f080bd-138d-4777-91bf-fb7e4b38cf13",
   "metadata": {},
   "source": [
    "## SageMaker JumpStart Mixtral 8x7b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "6065c4d5-7e62-485d-967a-02259226a1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Chunking document to fit Mixtral context window\n",
    "doc=[]\n",
    "docs=[]\n",
    "for k,v in document_holder.items():\n",
    "    doc.append(\"\\n\".join(v))\n",
    "for x in range(4):\n",
    "    docs.append(doc[30*(x):30*(x+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "1eee90cc-a28d-40b8-b968-f5f0dc6def63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The document is the Form 10-K annual report of Amazon.com, Inc. for the fiscal year ended December 31, 2022. The report provides detailed information about Amazon's business, financial performance, legal proceedings, risks, and other relevant information.\n",
      "\n",
      "1. Revenue and Profitability: Amazon's net sales for the year ended December 31, 2022, were $469.8 billion, an increase of 22% compared to the previous year. The company's net income for the year was $33.4 billion, compared to $21.3 billion in the previous year.\n",
      "2. Cash Flow: Amazon's cash and cash equivalents and marketable securities as of December 31, 2022, were $73.8 billion, an increase of 17% compared to the previous year. The company's operating cash flow for the year was $66.1 billion, an increase of 22% compared to the previous year.\n",
      "3. Debt and Solvency: As of December 31, 2022, Amazon had long-term debt of $60.2 billion, compared to $54.3 billion in the previous year. The company's debt-to-equity ratio was 1.17 as of December 31, 2022.\n",
      "4. Market and Industry Trends: Amazon operates in the rapidly evolving and intensely competitive marketplace, with competition from physical, e-commerce, and omnichannel retailers, publishers, vendors, distributors, manufacturers, and producers of the products offered and sold to consumers and businesses. The company also faces competition from web search engines, comparison shopping websites, social networks, web portals, and other online and app-based means of discovering, using, or acquiring goods and services.\n",
      "5. Future Outlook: Amazon's future growth depends on the continued growth of demand for the products and services offered by the company or its sellers, and the company's business is affected by general economic, business, and geopolitical conditions worldwide.\n",
      "6. Risks and Contingencies: The report identifies several risks and contingencies that could materially affect Amazon's business, financial condition, operating results, and cash flows, including legal proceedings, product liability claims, tax controversies, and government contracts. The report also notes that the company's operations are subject to general business regulations and laws, as well as regulations and laws specifically governing the Internet, physical, e-commerce, and omnichannel retail, digital content, web services, electronic devices, advertising, artificial intelligence technologies and services, and other products and services that the company offers or sells. These regulations and laws cover taxation, privacy, data use, data protection, data security, data localization, network security, consumer protection, pricing, content, copyrights, distribution, transportation, mobile communications, electronic device certification, electronic waste, energy consumption, environmental regulation, electronic contracts and other communications, competition, employment, trade and protectionist measures, web services, the provision of online payment services, registration, licensing, and information reporting requirements, unencumbered Internet access to the company's services or access to its facilities, the design and operation of websites, health, safety, and sanitation standards, the characteristics, legality, and quality of products and services, product labeling, the commercial operation of unmanned aircraft systems, healthcare, and other matters.</s> The document is a financial report for Amazon.com, Inc. for the year ended December 31, 2022.\n",
      "\n",
      "1. Revenue and Profitability: Amazon's net sales for the year ended December 31, 2022, were $513.983 billion, an increase of 9% compared to the prior year. The company's net loss for the year was $(2.722) billion, compared to net income of $33.364 billion in the prior year.\n",
      "2. Cash Flow: Amazon's cash provided by operating activities for the year ended December 31, 2022, was $46.752 billion, compared to $46.327 billion in the prior year. The company's cash used in investing activities for the year ended December 31, 2022, was $(37.601) billion, compared to $(58.154) billion in the prior year. Cash provided by financing activities for the year ended December 31, 2022, was $9.718 billion, compared to $6.291 billion in the prior year.\n",
      "3. Debt and Solvency: As of December 31, 2022, Amazon had long-term debt of $67.1 billion and long-term lease liabilities of $73.0 billion. The company's cash, cash equivalents, and marketable securities as of December 31, 2022, were $54.253 billion.\n",
      "4. Market and Industry Trends: The report highlights the impact of macroeconomic factors, including inflation, increased interest rates, significant capital market volatility, the prolonged COVID-19 pandemic, global supply chain constraints, and global economic and geopolitical developments, on Amazon's results of operations.\n",
      "5. Future Outlook: The report provides guidance for the first quarter of 2023, with net sales expected to be between $121.0 billion and $126.0 billion, and operating income expected to be between $0 and $4.0 billion.\n",
      "6. Risks and Contingencies: The report identifies various risks and contingencies, including fluctuations in foreign exchange rates, changes in global economic and geopolitical conditions, and changes in tax laws and regulations.\n",
      "\n",
      "In summary, Amazon's financial performance for the year ended December 31, 2022, was impacted by various macroeconomic factors, resulting in a net loss for the year. The company's cash flow remained strong, and it provided guidance for the first quarter of 2023. The report also highlighted various risks and contingencies that could impact the company's financial performance in the future.</s> The document is the Notes to Consolidated Financial Statements of Amazon.com, Inc. for the year ended December 31, 2022.\n",
      "\n",
      "1. Revenue and Profitability: Amazon.com, Inc. operates in three segments: North America, International, and AWS. The company's revenue for the year ended December 31, 2022, was $514 billion, an increase of 22% compared to the previous year. The net loss for the year was $2.7 billion, compared to a net income of $33.4 billion in the previous year.\n",
      "2. Cash Flow: The company generated $60.3 billion in cash from operations for the year ended December 31, 2022, an increase of 17% compared to the previous year. Capital expenditures for the year were $54.2 billion, an increase of 11% compared to the previous year.\n",
      "3. Debt and Solvency: As of December 31, 2022, the company had $69.5 billion of unsecured senior notes outstanding and $1.0 billion of borrowings under a secured revolving credit facility. The company's total long-term debt obligations were $70.5 billion as of December 31, 2022.\n",
      "4. Market and Industry Trends: The company operates in the e-commerce and cloud computing industries. The e-commerce industry is highly competitive, and the company faces competition from various brick-and-mortar and online retailers. The cloud computing industry is also highly competitive, and the company faces competition from various technology companies.\n",
      "5. Future Outlook: The company is focused on expanding its business and investing in various growth opportunities. The company is also investing in various initiatives, including building a satellite network for global broadband service and autonomous vehicles for ride-hailing services.\n",
      "6. Risks and Contingencies: The company is involved in various legal proceedings and regulatory investigations. The company is also subject to various risks, including risks related to its operations, financial condition, and business. The company is also exposed to various risks related to its significant investments in research and development, infrastructure, and content.\n",
      "\n",
      "Note: The above summary is based on the information provided in the document. The actual financial performance and future outlook of the company may differ from the information provided in the document.</s> The document appears to be a series of financial statements, reports, and disclosures for Amazon.com, Inc. for the year ended December 31, 2022. Here is a summary of the key points from the document:\n",
      "\n",
      "1. Revenue and Profitability: Amazon reported net sales of $513,983 million for the year ended December 31, 2022, representing an increase of 34% compared to the previous year. The company's net income for the year was $2,722 million, down from $33,364 million in the previous year.\n",
      "2. Cash Flow: Amazon generated $60,836 million in cash from operations for the year ended December 31, 2022, up from $51,151 million in the previous year. The company's investing activities resulted in cash outflows of $42,640 million, while its financing activities resulted in cash inflows of $10,571 million.\n",
      "3. Debt and Solvency: Amazon had long-term debt of $54,451 million as of December 31, 2022, up from $45,510 million in the previous year. The company's total stockholders' equity was $135,421 million as of December 31, 2022, up from $117,341 million in the previous year.\n",
      "4. Market and Industry Trends: The document does not provide specific information on market and industry trends. However, it does mention that Amazon operates in three segments: North America, International, and AWS.\n",
      "5. Future Outlook: The document does not provide specific information on the company's future outlook.\n",
      "6. Risks and Contingencies: The document identifies several risks and contingencies, including legal proceedings, tax contingencies, and changes in tax laws and regulations. The company is involved in various legal proceedings, including patent infringement lawsuits and investigations by tax authorities in various jurisdictions. The company has also established reserves for tax-related uncertainties based on estimates of whether, and the extent to which, additional taxes will be due.\n",
      "\n",
      "Overall, the document provides detailed financial information on Amazon's operations for the year ended December 31, 2022. However, it does not provide specific information on the company's future outlook or market and industry trends. The document also highlights several risks and contingencies that could impact the company's financial performance in the future.</s>"
     ]
    }
   ],
   "source": [
    "### Naive implementation of Map Reduce Summary\n",
    "answer=[]\n",
    "for doc in docs:\n",
    "    doc='\\n'.join(doc)\n",
    "    prompt=f\"\"\"<s><<SYS>>[INST]\n",
    "    You are a financial analyst, great at writing summaries of company financial performance.\n",
    "\n",
    "    Here is a document:\n",
    "    ######\n",
    "    {doc}\n",
    "    ######\n",
    "\n",
    "    Before responding:\n",
    "    1. Read the document several times to ensure you understand everything.\n",
    "    2. Take notes to identify the relevant information.<</SYS>>\n",
    "\n",
    "    Provide a comprehensive summary of the document.\n",
    "    Your summary should include the following if available in the document:\n",
    "    1. Revenue and Profitability\n",
    "    2. Cash Flow\n",
    "    3. Debt and Solvency\n",
    "    4. Market and Industry Trends\n",
    "    5. Future Outlook\n",
    "    6. Risks and Contingencies\n",
    "    Base your entire summary on the information provided in the document.[/INST]\"\"\"\n",
    "    payload = {\n",
    "           \"inputs\": prompt,\n",
    "            \"parameters\": {\"max_new_tokens\": 1000, \n",
    "                           # \"top_p\": 0.99 ,\n",
    "                           # \"temperature\": 0.1,\n",
    "                           \"return_full_text\": False,},\n",
    "        \"stream\": True\n",
    "        } \n",
    "    output=SAGEMAKER.invoke_endpoint_with_response_stream(Body=json.dumps(payload), EndpointName=\"mixtral\",ContentType=\"application/json\")\n",
    "    answer.append(jumpstart_streemer(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "8a2d93f3-4b93-426d-9097-d6c05c92c763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Revenue and Profitability: Amazon's net sales for the year ended December 31, 2022, were $469.8 billion (Form 10-K) or $513.983 billion (Financial Report), representing an increase compared to the previous year. However, the company's net income for the year was $33.4 billion (Form 10-K) or $2.722 billion (Financial Report), indicating a decrease in profitability.\n",
      "2. Cash Flow: Amazon generated $66.1 billion (Form 10-K) or $60.3 billion (Notes to Consolidated Financial Statements) in operating cash flow, representing an increase compared to the previous year. The company's investing activities resulted in cash outflows, while financing activities resulted in cash inflows.\n",
      "3. Debt and Solvency: Amazon had long-term debt of $60.2 billion (Form 10-K) or $70.5 billion (Notes to Consolidated Financial Statements) as of December 31, 2022. The company's total stockholders' equity was $135.421 billion (Notes to Consolidated Financial Statements) as of December 31, 2022.\n",
      "4. Market and Industry Trends: Amazon operates in the rapidly evolving and intensely competitive marketplace, with competition from various physical, e-commerce, and omnichannel retailers, publishers, vendors, distributors, manufacturers, and producers of the products offered and sold to consumers and businesses (Form 10-K). The company also faces competition from web search engines, comparison shopping websites, social networks, web portals, and other online and app-based means of discovering, using, or acquiring goods and services.\n",
      "5. Future Outlook: Amazon's future growth depends on the continued growth of demand for the products and services offered by the company or its sellers, and the company's business is affected by general economic, business, and geopolitical conditions worldwide (Form 10-K). The company is focused on expanding its business and investing in various growth opportunities (Notes to Consolidated Financial Statements).\n",
      "6. Risks and Contingencies: The report identifies several risks and contingencies that could materially affect Amazon's business, financial condition, operating results, and cash flows, including legal proceedings, product liability claims, tax controversies, and government contracts (Form 10-K). The company is involved in various legal proceedings, including patent infringement lawsuits and investigations by tax authorities in various jurisdictions (Notes to Consolidated Financial Statements).</s>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" 1. Revenue and Profitability: Amazon's net sales for the year ended December 31, 2022, were $469.8 billion (Form 10-K) or $513.983 billion (Financial Report), representing an increase compared to the previous year. However, the company's net income for the year was $33.4 billion (Form 10-K) or $2.722 billion (Financial Report), indicating a decrease in profitability.\\n2. Cash Flow: Amazon generated $66.1 billion (Form 10-K) or $60.3 billion (Notes to Consolidated Financial Statements) in operating cash flow, representing an increase compared to the previous year. The company's investing activities resulted in cash outflows, while financing activities resulted in cash inflows.\\n3. Debt and Solvency: Amazon had long-term debt of $60.2 billion (Form 10-K) or $70.5 billion (Notes to Consolidated Financial Statements) as of December 31, 2022. The company's total stockholders' equity was $135.421 billion (Notes to Consolidated Financial Statements) as of December 31, 2022.\\n4. Market and Industry Trends: Amazon operates in the rapidly evolving and intensely competitive marketplace, with competition from various physical, e-commerce, and omnichannel retailers, publishers, vendors, distributors, manufacturers, and producers of the products offered and sold to consumers and businesses (Form 10-K). The company also faces competition from web search engines, comparison shopping websites, social networks, web portals, and other online and app-based means of discovering, using, or acquiring goods and services.\\n5. Future Outlook: Amazon's future growth depends on the continued growth of demand for the products and services offered by the company or its sellers, and the company's business is affected by general economic, business, and geopolitical conditions worldwide (Form 10-K). The company is focused on expanding its business and investing in various growth opportunities (Notes to Consolidated Financial Statements).\\n6. Risks and Contingencies: The report identifies several risks and contingencies that could materially affect Amazon's business, financial condition, operating results, and cash flows, including legal proceedings, product liability claims, tax controversies, and government contracts (Form 10-K). The company is involved in various legal proceedings, including patent infringement lawsuits and investigations by tax authorities in various jurisdictions (Notes to Consolidated Financial Statements).</s>\""
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=f\"\"\"<s><<SYS>>[INST]\n",
    "You are a financial analyst, great at writing summaries of company financial performance.\n",
    "\n",
    "Here are multiple summaries of various parts of a documnet:\n",
    "######\n",
    "{\"#####\".join(answer)}\n",
    "######\n",
    "<</SYS>>\n",
    "Provide a coherent final summary that connects your individual summaries perfectly.\n",
    "Your final summary should follow the same outline:\n",
    "1. Revenue and Profitability\n",
    "2. Cash Flow\n",
    "3. Debt and Solvency\n",
    "4. Market and Industry Trends\n",
    "5. Future Outlook\n",
    "6. Risks and Contingencies\n",
    "[/INST]\"\"\"\n",
    "payload = {\n",
    "           \"inputs\": prompt,\n",
    "            \"parameters\": {\"max_new_tokens\": 1000, \n",
    "                           # \"top_p\": 0.99 ,\n",
    "                           # \"temperature\": 0.1,\n",
    "                           \"return_full_text\": False,},\n",
    "        \"stream\": True\n",
    "        } \n",
    "output=SAGEMAKER.invoke_endpoint_with_response_stream(Body=json.dumps(payload), EndpointName=\"SAGEMAKER ENDPOINT FOR MIXTRAL\",ContentType=\"application/json\")\n",
    "jumpstart_streemer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ae5ac-a94b-4d3d-ab8e-d67fbdfdaf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
